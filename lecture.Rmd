---
title: "Applications of Item Response Theory in *R*"
author: "W. Jake Thompson, Ph.D."
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    toc: true
    toc_float: true
    number_sections: false
bibliography: ["full-example/bib/refs.bib", "full-example/bib/packages.bib"]
biblio-style: apa
csl: full-example/csl/apa.csl
link-citations: yes
---

```{r setup, warning = FALSE, include = FALSE}
needed_packages <- c("tidyverse", "readxl", "here", "mirt", "furrr")
load_packages <- function(x) {
  if (!(x %in% installed.packages())) {
    install.packages(x, repos = "https://cran.rstudio.com/")
  }
  suppressPackageStartupMessages(require(x, character.only = TRUE))
}
vapply(needed_packages, load_packages, logical(1))

knitr::opts_chunk$set(
  echo = TRUE,
  fig.align = "c",
  out.width = "90%",
  fig.retina = 3,
  fig.path = "figures/"
)
```

```{r functions, include = FALSE}
inv_logit <- function(x) {
  1 / (1 + exp(-x))
}
icc_calc <- function(theta, itemid, a, b, c, u, .pb = NULL) {
  if ((!is.null(.pb)) && inherits(.pb, "Progress") && (.pb$i < .pb$n)) {
    .pb$tick()$print()
  }
  
  dat <- tibble(theta = theta, itemid = itemid, a = a, b = b, c = c, u = u)
  
  icc <- dat %>%
    unnest(cols = b) %>%
    mutate(exp_score = c + (1 - c) * inv_logit(a * (theta - b))) %>%
    add_row(exp_score = 1, .before = 1) %>%
    add_row(exp_score = 0) %>%
    rowid_to_column(var = "cat") %>%
    mutate(cat = cat - 1,
           theta = mean(theta, na.rm = TRUE),
           itemid = unique(itemid[!is.na(itemid)]),
           a = mean(a, na.rm = TRUE),
           c = mean(c, na.rm = TRUE),
           u = mean(u, na.rm = TRUE),
           p = exp_score - lead(exp_score, n = 1, default = 0)) %>%
    select(itemid, theta, cat, everything())

  return(icc)
}
sr_calc <- function(quad, n, prop, theta, itemid, a, b, c, u, .pb = NULL) {
  if ((!is.null(.pb)) && inherits(.pb, "Progress") && (.pb$i < .pb$n)) {
    .pb$tick()$print()
  }
  
  dat <- tibble(quad = quad, n = n, prop = prop, theta = theta, itemid = itemid,
                a = a, b = b, c = c, u = u)
  
  icc <- dat %>%
    unnest(cols = b) %>%
    mutate(exp_score = c + (1 - c) * inv_logit(a * (theta - b))) %>%
    add_row(exp_score = 1, .before = 1) %>%
    add_row(exp_score = 0) %>%
    rowid_to_column(var = "cat") %>%
    mutate(cat = cat - 1,
           theta = mean(theta, na.rm = TRUE),
           itemid = unique(itemid[!is.na(itemid)]),
           quad = mean(quad, na.rm = TRUE),
           n = mean(n, na.rm = TRUE),
           prop = mean(prop, na.rm = TRUE),
           a = mean(a, na.rm = TRUE),
           c = mean(c, na.rm = TRUE),
           u = mean(u, na.rm = TRUE),
           cat_p = exp_score - lead(exp_score, n = 1, default = 0),
           p = cat * cat_p,
           var = cat_p * (1 - cat_p)) %>%
    select(itemid, theta, cat, everything()) %>%
    group_by(quad, itemid, n, prop) %>%
    summarize(max_score = max(cat) - 1, theta = mean(theta), p = sum(p),
              var = sum(var)) %>%
    ungroup() %>%
    mutate(se = sqrt(var / n),
           df = 1,
           sr = (prop - p) / se,
           bar_top = min(max_score, p + (1.96 * se)),
           bar_bottom = max(0, p - (1.96 * se)),
           chisq = sr^2)

  return(icc)
}
sr_plot <- function(itemid, itemtype, NIS, maxscore, sr_data, icc_data) {
  icc_data <- icc_data %>%
    group_by(theta) %>%
    summarize(exp_score = sum(p * cat))
  
  sr_summary <- sr_data %>%
    summarize(chisq = sum(chisq),  df = sum(df)) %>%
    mutate(pvalue = pchisq(chisq, df, lower.tail = FALSE),
           chisq = sprintf("%0.1f", chisq),
           pvalue = sprintf("%0.3f", pvalue),
           pvalue = case_when(pvalue == "0.000" ~ "< 0.001",
                              TRUE ~ paste0("= ", pvalue)))
  
  subtitle <- bquote(.(itemid) * "; " ~ chi[(.(sr_summary$df))]^2 ~ "=" ~
                       .(sr_summary$chisq) * "," ~ italic(p) ~ 
                       .(sr_summary$pvalue))
  
  plot <- ggplot(icc_data, aes(x = theta, y = exp_score)) +
    geom_line(size = 2) +
    geom_errorbar(data = sr_data, inherit.aes = FALSE,
                  mapping = aes(x = theta, ymin = bar_bottom, ymax = bar_top),
                  color = "#E69F00", width = 0.2, size = 1) +
    geom_point(data = sr_data, mapping = aes(y = prop), color = "#56B4E9",
               size = 3) +
    scale_x_continuous(breaks = seq(-3, 3, by = 1)) +
    expand_limits(y = c(0, (NIS - 1))) +
    labs(x = expression(theta),
         y = expression(paste("P(X >= x | ", theta, ")")),
         title = "Standardized Residuals",
         subtitle = subtitle,
         color = "Score") +
    theme_bw() +
    theme(legend.position = "bottom")
  
  return(plot)
}
```

This document provides and overview of how to estimate a 3-parameter logistic (3PL) item response theory (IRT) model in *R*. For illustrative purposes, we also limit this example to dichotomously scored items in order to simplify the problem while learning the software. A more complete example with polytomous items and additional analyses (e.g., information, reliability, model fit, etc.) can be found in the `full-example` directory. Most data cleaning and manipulation will utilize a suite a packages known as the **tidyverse** [@tidyverse2019]. The IRT analysis will use the **mirt** package [@mirt2012].


## Data Cleaning

The first step of any analysis is to read in the data. For this example, we will use a balanced sample of males and females from a large scale operational assessment. This data set contains 5,000 respondents to 40 items assessing the respondents' knowledge and understandings of engineering design. Also included is a file of metadata, describing the 40 items.

```{r read-data}
ied <- read_csv(here("data", "IED_data.csv"),
                col_types = cols(.default = col_integer(),
                                 gender = col_character()))
meta <- read_excel(here("data", "metadata.xlsx"), sheet = "IED")
```

Because we want to use only dichotomously scored items, we need to remove any polytomous items from the data set. In the `meta` data, the `NIS` variable includes the number of score categories. To identify the dichotomous items, we can pull the `itemid`s for cases where `NIS` is equal to 2.

```{r identify-dichot}
dichot_items <- meta %>%
  filter(NIS == 2) %>%
  pull(itemid) %>%
  as.character()
```

We can then create a new data set for modeling by selecting only the demographic variables and the dichotomous items from the `ied` data. We also need to clean the response data. In the `ied` data, missing values have been coded a `-9`. The `na_if` function can be used to replace a given value with *R*'s internal representation of missing values, `NA`.

```{r clean-data}
clean_ied <- ied %>%
  select(studentid, gender, {{dichot_items}}) %>%
  mutate_all(~na_if(.x, -9))
```


## Estimate IRT Model

We next have to specify how each item will be modeled. In this example, every item will be estimated using the 3PL IRT model [@birnbaum_1968]. To specify item models, we create of vector model recognized by **mirt**. Conveniently, the 3PL model is denoted `3PL`. Because all items have the same model, we create a vector that repeats `3PL` once for each item. For a list of available models, see [`?mirt()`](https://rdrr.io/cran/mirt/man/mirt.html).

```{r mirt-type}
mirt_type_3pl <- rep("3PL", length(dichot_items))
mirt_type_2pl <- rep("2PL", length(dichot_items))
mirt_type_1pl <- rep("Rasch", length(dichot_items))
```

To estimate the IRT model, we'll use the **mirt** package [@R-mirt]. This function requires that the data include only item responses, so we'll create a data set, `model_data`, that is the same as the original data but with the `studentid` and `gender` columns removed.

```{r mirt-data}
model_data <- clean_ied %>%
  select(-studentid, -gender)
```

We are now ready to estimate the model. The first argument is the `data`, which we specify as the `model_data` we just created. Next, the actual model must be specified. Because we are using a unidimensional model, we have only one factor, called `F1`. This factor is measured by items 1 through the number of columns in our `model_data`, in this case, 29. We can then specify prior distributions for each parameter. This makes the estimation more efficient by setting reasonable distributions we might expect the item parameters to fall within. The **mirt** package defines the IRT model using the slope intercept form shown equation \@ref(eq:3pl-slope).

\begin{equation}
  \Pr(Y_{ij}=1|\alpha_i, \beta_i, \gamma_i, \theta_j) =
  \frac{\exp(\gamma_i)}{1 + \exp(\gamma_i)} +
  \frac{1}{1 + \exp(\gamma_i)}
  \frac{\exp(\alpha_i\theta_j + \beta_i)}{1 + \exp(\alpha_i\theta_j + \beta_i)}
  (\#eq:3pl-slope)
\end{equation}

This is in contrast to the more traditional parameterization shown in equation \@ref(eq:3pl).

\begin{equation}
  \Pr(Y_{ij}=1|a_i, b_i, c_i, \theta_j) =
  c_i + (1 - c_i)
  \frac{\exp\{a_i(\theta_j - b_i)\}}{1 + \exp\{a_i(\theta_j - b_i)\}}
  (\#eq:3pl)
\end{equation}

Thus, we must define our prior on the scale of the estimated parameters in equation \@ref(eq:3pl-slope), and then transform back onto the more common parameterization. The transformation between the parameterizations in equation \@ref(eq:3pl-slope) and equation \@ref(eq:3pl) is given in equation \@ref(eq:irt-transform).

\begin{equation}
  \begin{split}
  a_i = \alpha_i
  \end{split}
  \quad\quad
  \begin{split}
  b_i = - \frac{\beta_i}{\alpha_i}
  \end{split}
  \quad\quad
  \begin{split}
  c_i = \frac{\exp(\gamma_i)}{1 + \exp(\gamma_i)}
  \end{split}
  (\#eq:irt-transform)
\end{equation}


For the $\alpha$ parameter, we define a lognormal prior with a mean of 0 and a standard deviation of 1. The $\beta$ parameter (called $d$ in **mirt**) is given a normal prior with a mean of 0 and a standard deviation of 2. Finally, $\gamma$ is given a normal prior with a mean of -1.39 and standard deviation. These priors for parameterization in equation \@ref(eq:3pl) are shown in Figure \@ref(fig:prior-dist).
 
```{r model-spec}
model_spec_3pl <- mirt.model("F1 = 1-29
                              PRIOR = (1-29, a1, lnorm, 0, 1),
                                      (1-29, d, norm, 0, 2),
                                      (1-29, g, norm, -1.39, 1)")
model_spec_2pl <- mirt.model("F1 = 1-29
                              PRIOR = (1-29, a1, lnorm, 0, 1),
                                      (1-29, d, norm, 0, 2)")
model_spec_1pl <- mirt.model("F1 = 1-29
                              PRIOR = (1-29, d, norm, 0, 2)")
```

(ref:prior-dist-cap) Prior distributions for the 3PL IRT model, as defined in `model_spec`.

```{r prior-dist, fig.cap = "(ref:prior-dist-cap)", echo = FALSE, cache = TRUE}
tibble(alpha = rlnorm(1000000, meanlog = 0, sdlog = 1),
       beta = rnorm(1000000, mean = 0, sd = 2),
       gamma = rnorm(1000000, mean = -1.39, sd = 1)) %>%
  mutate(a = alpha,
         b = -1 * (beta / alpha),
         c = exp(gamma) / (1 + exp(gamma)),
         keep = a <= 8 & between(b, -8, 8)) %>%
  filter(keep) %>%
  select(a:c) %>%
  pivot_longer(everything(), names_to = ".variable", values_to = "value") %>%
  ggplot(aes(x = value)) +
  stat_density(geom = "line") +
  facet_wrap(~.variable, nrow = 1, scales = "free") +
  labs(x = "Parameter Value", y = "Density") +
  theme_bw()
```

Next, for each item, we specify what the item type is. We calculated this when we created the `mirt_type` vector. Finally, we'll set a random seed to make sure we all get the same results (they should be pretty close without this).

```{r fit-mirt, results = "hide", cache = TRUE}
model_3pl <- mirt(data = model_data, model = model_spec_3pl,
                  itemtype = mirt_type_3pl, technical = list(set.seed = 9416))

model_2pl <- mirt(data = model_data, model = model_spec_2pl,
                  itemtype = mirt_type_2pl, technical = list(set.seed = 9416))

model_1pl <- mirt(data = model_data, model = model_spec_1pl,
                  itemtype = mirt_type_1pl, technical = list(set.seed = 9416))
```

Now we've estimated the model!

```{r show-model}
model_3pl
```


### IRT Parameters

The default output is not incredibly useful. What we ultimately want are the estimated item and person parameters. We'll focus first on item parameters.

#### Item Parameters

We can extract the item parameters by the using the `coef()` function. For each item, we see the slope (`a1`), intercept (`d`), and guessing parameter `g`.

```{r default-coef}
coef(model_3pl)
```

Often, it is more useful to think about the parameters using the more well known $a$, $b$, and $c$ parameters. These can be retrieved by setting `IRTpars = TRUE`.

```{r irt-coef}
coef(model_3pl, IRTpars = TRUE)
coef(model_2pl, IRTpars = TRUE)
coef(model_1pl, IRTpars = TRUE)
```

The last problem to solve is that the coefficients are returned in a list format. This is done because, depending on the estimated model, not every item will have the same set of parameters (e.g., if we included polytomous items). Thus, for consistency, the **mirt** package always returns the parameters in a list format, which can handle any configuration of parameters. However, with some **tidyverse** magic, we can create a data frame that has one row per item since all of our items have the same set of parameters.

```{r item-params}
item_params_3pl <- coef(model_3pl, IRTpars = TRUE) %>%
  list_modify(GroupPars = zap()) %>%
  imap_dfr(function(x, y) {
    as_tibble(x) %>%
      add_column(itemid = y, .before = 1) %>%
      select(itemid, a, b, everything())
  }) %>%
  rename(c = g) %>%
  replace_na(list(c = 0, u = 1))

item_params_2pl <- coef(model_2pl, IRTpars = TRUE) %>%
  list_modify(GroupPars = zap()) %>%
  imap_dfr(function(x, y) {
    as_tibble(x) %>%
      add_column(itemid = y, .before = 1) %>%
      select(itemid, a, b, everything())
  }) %>%
  rename(c = g) %>%
  replace_na(list(c = 0, u = 1))

item_params_1pl <- coef(model_1pl, IRTpars = TRUE) %>%
  list_modify(GroupPars = zap()) %>%
  imap_dfr(function(x, y) {
    as_tibble(x) %>%
      add_column(itemid = y, .before = 1) %>%
      select(itemid, a, b, everything())
  }) %>%
  rename(c = g) %>%
  replace_na(list(c = 0, u = 1))
```

#### Person Parameters

We are also likely interested in the person parameters, or the respondent ability estimates. We can extract the ability estimates using the `fscores()` function. When then do some formatting to get the scores into a nice data frame, and add a `studentid` column so we can keep track of which ability estimate goes with each respondent.

```{r person-params}
person_params_1pl <- fscores(model_1pl) %>%
  as_tibble(.name_repair = ~"theta") %>%
  rowid_to_column(var = "studentid")

person_params_2pl <- fscores(model_2pl) %>%
  as_tibble(.name_repair = ~"theta") %>%
  rowid_to_column(var = "studentid")

person_params_3pl <- fscores(model_3pl) %>%
  as_tibble(.name_repair = ~"theta") %>%
  rowid_to_column(var = "studentid")
```

## Item Regressions

```{r}
icc_3pl <- item_params_3pl %>%
  pmap(function(itemid, a, b, c, u) {
    tibble(theta = seq(-3, 3, by = 0.01)) %>%
      mutate(prob = c + (1 - c) * inv_logit(a * (theta - b))) %>%
      ggplot(aes(x = theta, y = prob)) +
        geom_line(size = 2) +
        scale_x_continuous(breaks = seq(-3, 3, by = 1)) +
        expand_limits(y = c(0, 1)) +
        labs(x = expression(theta),
             y = expression(paste("P(X >= x | ", theta, ")")),
             title = paste("Item", itemid)) +
        theme_bw()
  })

icc_2pl <- item_params_2pl %>%
  pmap(function(itemid, a, b, c, u) {
    tibble(theta = seq(-3, 3, by = 0.01)) %>%
      mutate(prob = c + (1 - c) * inv_logit(a * (theta - b))) %>%
      ggplot(aes(x = theta, y = prob)) +
        geom_line(size = 2) +
        scale_x_continuous(breaks = seq(-3, 3, by = 1)) +
        expand_limits(y = c(0, 1)) +
        labs(x = expression(theta),
             y = expression(paste("P(X >= x | ", theta, ")")),
             title = paste("Item", itemid)) +
        theme_bw()
  })

icc_1pl <- item_params_1pl %>%
  pmap(function(itemid, a, b, c, u) {
    tibble(theta = seq(-3, 3, by = 0.01)) %>%
      mutate(prob = c + (1 - c) * inv_logit(a * (theta - b))) %>%
      ggplot(aes(x = theta, y = prob)) +
        geom_line(size = 2) +
        scale_x_continuous(breaks = seq(-3, 3, by = 1)) +
        expand_limits(y = c(0, 1)) +
        labs(x = expression(theta),
             y = expression(paste("P(X >= x | ", theta, ")")),
             title = paste("Item", itemid)) +
        theme_bw()
  })

icc_3pl[[1]]
icc_2pl[[1]]
icc_1pl[[1]]
```

## Standardized Residuals

```{r}
iccs <- crossing(theta = seq(-3, 3, by = 0.01),
                 itemid = colnames(model_data)) %>%
  left_join(item_params_1pl, by = "itemid") %>%
  future_pmap_dfr(icc_calc, .progress = TRUE) %>%
  nest(icc_data = -c(itemid))
```


```{r}
person_groups <- person_params_1pl %>%
  mutate(group = cut_interval(theta, n = 10),
         quad = as.numeric(group))

quad_summary <- clean_ied %>%
  pivot_longer(cols = -c(studentid, gender),
               names_to = "item", values_to = "score") %>%
  filter(!is.na(score)) %>%
  left_join(select(person_groups, studentid, theta, quad), by = "studentid") %>%
  group_by(quad, item) %>%
  summarize(n = n(), total_score = sum(score), total_theta = sum(theta)) %>%
  ungroup() %>%
  mutate(prop = case_when(n < 5 ~ NA_real_,
                          TRUE ~ total_score / n),
         theta = case_when(n < 5 ~ NA_real_,
                           TRUE ~ total_theta / n))

srs <- quad_summary %>%
  select(quad, n, prop, theta, itemid = item) %>%
  left_join(item_params_1pl, by = "itemid") %>%
  pmap_dfr(sr_calc) %>%
  nest(sr_data = -c(itemid)) %>%
  left_join(iccs, by = "itemid")

sr_plots <- meta %>%
  select(itemid, itemtype, NIS, maxscore) %>%
  filter(NIS == 2)  %>%
  left_join(mutate(srs, itemid = as.double(itemid)), by = "itemid") %>%
  pmap(sr_plot)

walk(sr_plots, print)

pdf("~/Desktop/1pl-sr.pdf", width = 6, height =6)
for(i in 1:length(sr_plots)) {
  print(sr_plots[[i]])
}
dev.off()
```


## Other Methods for IRT in *R*

The **mirt** package is not the only way to estimate IRT models in *R*. @choi_2019 provides a thorough overview of 45 *R* packages that can be used to conduct analyses using IRT including differential item functioning and equating. The paper also discusses the features available in each package, making this an excellent resource when trying to find a package to complete a specific analysis.

For more advanced work and better methods for model fit, Bayesian modeling offers much more flexibility. The *Stan* probabilistic programming language [@stan] offers one way to define these models in *R* with the **rstan** package [@R-rstan]. The **brms** package also offers an interface to *Stan* for estimating linear and non-linear multilevel models, without having to learn the *Stan* language [@R-brms; @brms2017; @brms2018]. @burkner_2019 provides a comprehensive overview of how to specify, estimate, and evaluate IRT models, along with comparisons to other *R* packages.


## References {-}

```{r write-packages, include = FALSE, eval = FALSE}
if (!file.exists("bib/packages.bib")) file.create("bib/packages.bib")
suppressWarnings(
  knitr::write_bib(c(.packages(), "rstan", "brms"), "bib/packages.bib")
)

# Correct capitalization in packages
read_lines("bib/packages.bib") %>%
  str_replace_all("mirt:", "{mirt}:") %>%
  str_replace_all("brms:", "{brms}:") %>%
  str_replace_all("ggplot2:", "{ggplot2}:") %>%
  str_replace_all(" Stan", " {Stan}") %>%
  str_replace_all("rstan:", "{RStan}:") %>%
  str_replace_all("rstanarm:", "{RStanArm}:") %>%
  str_replace_all("Bayesian", "{Bayesian}") %>%
  str_replace_all("loo:", "{loo}:") %>%
  str_replace_all("WAIC", "{WAIC}") %>%
  write_lines("bib/packages.bib")
```

<div id="refs"></div>
